(window.webpackJsonp=window.webpackJsonp||[]).push([[60],{374:function(t,s,n){"use strict";n.r(s);var a=n(0),e=Object(a.a)({},function(){var t=this,s=t.$createElement,n=t._self._c||s;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h1",{attrs:{id:"附录-a：transducing"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#附录-a：transducing","aria-hidden":"true"}},[t._v("#")]),t._v(" 附录 A：Transducing")]),t._v(" "),n("p",[t._v("与我们在本书中所讲解的内容相比，Transducing 是一种更高级的技术。它扩展了"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch9.html"}},[t._v("第九章")]),t._v("中的列表操作的许多概念。")],1),t._v(" "),n("p",[t._v("我不一定会称这个话题是严格的 “轻量函数式”，它更像是在此之上的额外福利。我将它留作附录是因为你很可能需要暂且跳过关于它的讨论，而在你对本书正文中的概念感到相当适应 —— 并且确实经过实践！ —— 之后再回到这里。")]),t._v(" "),n("p",[t._v("老实说，即便是教授了 transducing 许多次，而且编写了这一章之后，我依然在努力地尝试使用这种技术来武装自己的头脑。所以，如果它让你感到很绕也不要灰心。给这一章夹上一个书签，当你准备好了之后再回来。")]),t._v(" "),n("p",[t._v("Transducing 意味着带有变形（transforming）的递减（reduction）。")]),t._v(" "),n("p",[t._v("我知道，它听起来就像一个杂乱的词汇 —— 它使人糊涂的地方要比它澄清的东西多。但还是让我们看看它能有多么强大。实际上，我认为一旦你掌握了轻量函数式编程的原理，它就是你能力的最佳展示。")]),t._v(" "),n("p",[t._v("正如本书的其他部分一样，我的方式是首先解释 "),n("em",[t._v("为什么")]),t._v("，然后在讲解 "),n("em",[t._v("如何做")]),t._v("，最后归结为一种简化的，可重用的 "),n("em",[t._v("什么")]),t._v("。这通常与其他许多人的教授方法相反，但我认为这种方式可以使你更深入地学习。")]),t._v(" "),n("h2",{attrs:{id:"首先，为什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#首先，为什么","aria-hidden":"true"}},[t._v("#")]),t._v(" 首先，为什么")]),t._v(" "),n("p",[t._v("让我们从扩展"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch3.md/#user-content-shortlongenough"}},[t._v("第三章中的一个场景")]),t._v("开始，测试一个单词，看它是否足够短并/或足够长：")],1),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" str"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" str"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("在"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch3.md/#user-content-shortlongenough"}},[t._v("第三章中，我们使用了这些判定函数")]),t._v("来测试一个单词。然后在第九章中，我们学习了如何"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch9.md/#filter"}},[t._v("使用 "),n("code",[t._v("filter(..）")]),t._v(" 之类的列表操作")]),t._v("重复这样的测试。例如：")],1),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"You"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"have"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"written"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"something"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"very"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"interesting"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nwords\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["written","something"]')]),t._v("\n")])])]),n("p",[t._v("这可能不太明显，不过这种分离且相邻的列表操作模式有些不尽人意的性质。当我们处理仅拥有为数不多的值的单一数组时，一切都很正常。但如果数组中有许多值的时候，分离地处理每个 "),n("code",[t._v("filter(..)")]),t._v(" 可能会出人意料地降低程序运行的速度。")]),t._v(" "),n("p",[t._v("当我们的数组是异步/懒惰（也称为 observable）的，在对事件作出相应而跨时段处理值（见"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch10.html"}},[t._v("第十章")]),t._v("）的时候也会出现同样的性能问题。在这种场景下，事件流中每次只会有一个值被传递出来，所以使用两个分离的 "),n("code",[t._v("filter(..)")]),t._v(" 函数处理这些离散的值也不是什么大问题。")],1),t._v(" "),n("p",[t._v("但微妙的是，每个 "),n("code",[t._v("filter(..)")]),t._v(" 方法都生成一个分离的 observable。将一个值从一个 observable 中传递到另一个 observable 的开销可能累积起来。特别是在这些情况下成千或上百万的值需要被处理并非不寻常的事；即便是如此之小的开销也会很快地累积起来。")]),t._v(" "),n("p",[t._v("另一个缺陷是可读性，特别是当我们需要对多个列表（或者 observable）重复这一系列操作的时候。例如：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("zip")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    list1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    list2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    list3"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[t._v("很啰嗦，对吧？")]),t._v(" "),n("p",[t._v("如果我们能够将 "),n("code",[t._v("isLongEnough(..)")]),t._v(" 和 "),n("code",[t._v("isShortEnough(..)")]),t._v(" 判定函数结合起来不是更好吗（对于可读性和性能两方面来说）？你可以手动这样做：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isCorrectLength")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("但这不是 FP 的方式！")]),t._v(" "),n("p",[t._v("在"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch9.md/#fusion"}},[t._v("第九章中，我们谈到了熔合")]),t._v(" —— 组合相邻的映射函数。回想一下：")],1),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("pipe")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" removeInvalidChars"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" upper"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" elide "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("不幸的是，组合相邻的判定函数不像组合相邻的映射函数那么简单。究其原因，考虑一下判定函数的 “外形（shape）” —— 某种描述输入和输出签名的学术化方式。它接收一个单独的值，并返回一个 "),n("code",[t._v("true")]),t._v(" 或 "),n("code",[t._v("false")]),t._v("。")]),t._v(" "),n("p",[t._v("如果你试着使用 "),n("code",[t._v("isShortEnough(isLongEnough(str))")]),t._v("，它是不会正常工作的。"),n("code",[t._v("isLongEnough(..)")]),t._v(" 将会返回 "),n("code",[t._v("true")]),t._v(" / "),n("code",[t._v("false")]),t._v("，而不是 "),n("code",[t._v("isShortEnough(..)")]),t._v(" 所期待的字符串值。扫兴。")]),t._v(" "),n("p",[t._v("在组合相邻的递减函数时也存在相似的恼人之处。递减函数的 “外形” 是一个接收两个输入值的函数，并返回一个组合好的值。递减函数的单值输出不适于作为另一个期待两个值的递减函数的输入。")]),t._v(" "),n("p",[t._v("另外，"),n("code",[t._v("reduce(..)")]),t._v(" 帮助函数接收一个可选的输入 "),n("code",[t._v("initialValue")]),t._v("。有时它可以被省略，但有时不得不被传入。这使组合变得更复杂，因为一个递减操作可能需要一个 "),n("code",[t._v("initialValue")]),t._v(" 而另一个递减操作可能需要一个不同的 "),n("code",[t._v("initialValue")]),t._v("。我们如何才能使用某种组合好的递减函数来发起一个 "),n("code",[t._v("reduce(..)")]),t._v(" 调用呢？")]),t._v(" "),n("p",[t._v("考虑一个这样链条：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// "WRITTENSOMETHING"')]),t._v("\n")])])]),n("p",[t._v("你能想象一个包含所有 "),n("code",[t._v("map(strUppercase)")]),t._v("、"),n("code",[t._v("filter(isLongEnough)")]),t._v("、"),n("code",[t._v("filter(isShortEnough)")]),t._v("、"),n("code",[t._v("reduce(strConcat)")]),t._v(" 这些步骤的组合吗？每一个操作函数的外形都是不同的，所以它们不能直接组合在一起。我们需要调整一下它们的外形来使它们彼此吻合。")]),t._v(" "),n("p",[t._v("希望这些观察展示了为什么单纯的熔合式组合不能完成这个任务。我们需要更强大的技术，而 transducing 就是工具。")]),t._v(" "),n("h2",{attrs:{id:"接下来，如何做"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#接下来，如何做","aria-hidden":"true"}},[t._v("#")]),t._v(" 接下来，如何做")]),t._v(" "),n("p",[t._v("让我们来谈谈如何才能衍生出一种映射函数、判定函数和/或递减函数的组合。")]),t._v(" "),n("p",[t._v("不要被冲昏了头脑：你不必在你自己的程序中把我们将要探索的所有这些思维步骤都走一遍。一旦你理解并能够认出 trasnducing 解决的问题，你就可以直接跳到使用一个 FP 库的 "),n("code",[t._v("transduce(..)")]),t._v(" 工具，并继续处理你程序的其余部分！")]),t._v(" "),n("p",[t._v("让我们开始吧。")]),t._v(" "),n("h3",{attrs:{id:"将映射-过滤表达为递减"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#将映射-过滤表达为递减","aria-hidden":"true"}},[t._v("#")]),t._v(" 将映射/过滤表达为递减")]),t._v(" "),n("p",[t._v("我们要施展的第一个技巧是将 "),n("code",[t._v("filter(..)")]),t._v(" 和 "),n("code",[t._v("map(..)")]),t._v(" 调用表达为 "),n("code",[t._v("reduce(..)")]),t._v(" 调用。回忆一下"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch9.md/#map-as-reduce"}},[t._v("我们在第九章中是如何做的")]),t._v("：")],1),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" str"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toUpperCase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strConcat")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" str1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" str2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercaseReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nwords\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercaseReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// "WRITTENSOMETHING"')]),t._v("\n")])])]),n("p",[t._v("这是个相当好的改进。我们现在有了四个相邻的 "),n("code",[t._v("reduce(..)")]),t._v(" 调用而不是拥有不同外形的三种不同方法的混合。但是，我们依然不能简单地 "),n("code",[t._v("compose(..)")]),t._v(" 这四个递减函数，因为它们接收两个参数而不是一个。")]),t._v(" "),n("p",[n("a",{attrs:{name:"cheating"}})]),t._v(" "),n("p",[t._v("在"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch9.md/#user-content-reducecheating"}},[t._v("第九章中，我们作弊")]),t._v("并使用了 "),n("code",[t._v("list.push(..)")]),t._v(" 作为一种副作用进行改变数组，而不是创建一个全新的数组并在上面连接。现在让我们更正式一些：")],1),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercaseReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" str "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("稍后，我们将看看创建新数组（例如，"),n("code",[t._v("[...list,str]")]),t._v("）来进行连接在这里是否必要。")]),t._v(" "),n("h3",{attrs:{id:"将递减函数参数化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#将递减函数参数化","aria-hidden":"true"}},[t._v("#")]),t._v(" 将递减函数参数化")]),t._v(" "),n("p",[t._v("两个过滤递减函数除了使用一个不同的判定函数以外几乎是相同的。让我们将此参数化，这样我们就得到一个可以定义任意过滤递-减函数的工具：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isLongEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("为了得到一个能够生成任意映射-递减函数的工具，让我们对 "),n("code",[t._v("mapperFn(..)")]),t._v(" 进行相同的参数化：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" strToUppercaseReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("我们链条看起来没变：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercaseReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("h3",{attrs:{id:"抽取共通的组合逻辑"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#抽取共通的组合逻辑","aria-hidden":"true"}},[t._v("#")]),t._v(" 抽取共通的组合逻辑")]),t._v(" "),n("p",[t._v("很仔细地观察上面的 "),n("code",[t._v("mapReducer(..)")]),t._v(" 和 "),n("code",[t._v("filterReducer(..)")]),t._v(" 函数。你发现它们共享的共通功能了吗？")]),t._v(" "),n("p",[t._v("这一部分：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 或者")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("让我们为这个共同逻辑定义一个帮助函数。但我们如何称呼它？")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token constant"}},[t._v("WHATSITCALLED")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("检视一下 "),n("code",[t._v("WHATSITCALLED(..)")]),t._v(" 函数在做什么，它接收两个值（一个数组和另一个值）并通过创建一个新数组并将值连接到它末尾来将它们 “结合”。非常没有创意，但我们可以将它命名为 "),n("code",[t._v("listCombine(..)")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("现在让我们重新定义递减函数的帮助函数，来使用 "),n("code",[t._v("listCombine(..)")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("我们的链条依然没变（所以我们不再啰嗦这一点）。")]),t._v(" "),n("h3",{attrs:{id:"将组合参数化"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#将组合参数化","aria-hidden":"true"}},[t._v("#")]),t._v(" 将组合参数化")]),t._v(" "),n("p",[t._v("我们简单的 "),n("code",[t._v("listCombine(..)")]),t._v(" 工具只是我们结合两个值的一种可能的方式。让我们将使用它的过程参数化，来时我们的递减函数更加一般化：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("mapperFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("predicateFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("要使用这种形式的帮助函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" strToUppercaseReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isLongEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("将这些工具定义为接收两个参数而非一个对于组合来说不太方便，所以让我们使用我们的 "),n("code",[t._v("curry(..)")]),t._v(" 方式：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" curriedMapReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("mapperFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" curriedFilterReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("predicateFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" strToUppercaseReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedMapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isLongEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" isShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("这看起来烦冗了一些，而且看起来可能不是非常有用。")]),t._v(" "),n("p",[t._v("但是为了进行到我们衍生物的下一步来说这实际上是必要的。记住，我们这里的终极目标是能够 "),n("code",[t._v("compose(..)")]),t._v(" 这些递减函数，我们就快成功了。")]),t._v(" "),n("h3",{attrs:{id:"组合柯里化后的函数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#组合柯里化后的函数","aria-hidden":"true"}},[t._v("#")]),t._v(" 组合柯里化后的函数")]),t._v(" "),n("p",[t._v("这一步是所有思考中最刁钻的一步。所以这里要慢慢读并集中注意力。")]),t._v(" "),n("p",[t._v("让我们考虑一下刚才柯里化后的函数，但不带 "),n("code",[t._v("listCombine(..)")]),t._v(" 函数被传入的部分：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedMapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" z "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("考虑所有这三个中间函数的外形，"),n("code",[t._v("x(..)")]),t._v("、"),n("code",[t._v("y(..)")]),t._v("、和 "),n("code",[t._v("z(..)")]),t._v("。每一个都期待一个单独的组合函数，并为它生成一个递减函数。")]),t._v(" "),n("p",[t._v("记住，如果我们想要得到所有这些函数的独立的递减函数，我们可以这样做：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" upperReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("x")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" longEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("y")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" shortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("z")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("但如果没有调用 "),n("code",[t._v("y(listCombine)")]),t._v("，而是调用了 "),n("code",[t._v("y(z)")]),t._v(" 你会得到什么？基本上是说，当将 "),n("code",[t._v("z")]),t._v(" 作为 "),n("code",[t._v("y(..)")]),t._v(" 的 "),n("code",[t._v("combinerFn(..)")]),t._v(" 传入时发生了什么？这会返回一个内部看起来像这样的递减函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("z")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("看到内部的 "),n("code",[t._v("z(..)")]),t._v(" 调用了吗？这在你看来应当是错的，因为 "),n("code",[t._v("z(..)")]),t._v(" 函数本应只接收一个参数（一个 "),n("code",[t._v("combinerFn(..)")]),t._v("），不是两个（"),n("code",[t._v("list")]),t._v(" 和 "),n("code",[t._v("val")]),t._v("）。外形不匹配。这不能工作。")]),t._v(" "),n("p",[t._v("相反让我们看看组合 "),n("code",[t._v("y(z(listCombine))")]),t._v("。我们将它分解为两个分离的步骤：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" shortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("z")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" longAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("y")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" shortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("我们创建了 "),n("code",[t._v("shortEnoughReducer(..)")]),t._v("，然后我们将它作为 "),n("code",[t._v("combinerFn(..)")]),t._v(" 传递给 "),n("code",[t._v("y(..)")]),t._v(" 而非调用 "),n("code",[t._v("y(listCombine)")]),t._v("；这个新的调用生成了 "),n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v("。将这一句重读几遍，直到你领悟为止。")]),t._v(" "),n("p",[t._v("现在考虑一下："),n("code",[t._v("shortEnoughReducer(..)")]),t._v(" 和 "),n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v("内部看起来什么样？你能在思维中看到它们吗？")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// shortEnoughReducer，来自 z(..) 调用:")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isShortEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// longAndShortEnoughReducer，来自 y(..) 调用:")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("isLongEnough")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("shortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("你看到 "),n("code",[t._v("shortEnoughReducer(..)")]),t._v(" 是如何在 "),n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v(" 内部取代了 "),n("code",[t._v("listCombine(..)")]),t._v(" 吗？为什么这个好用？")]),t._v(" "),n("p",[t._v("因为 "),n("strong",[t._v("一个 "),n("code",[t._v("reducer(..)")]),t._v(" 的外形和 "),n("code",[t._v("listCombine(..)")]),t._v(" 的外形是相同的。")]),t._v(" 换言之，一个递减函数可以被用作另一个递减函数的组合函数；这就是它们如何组合的！"),n("code",[t._v("listCombine(..)")]),t._v(" 函数制造了第一个递减函数，然后这个递减函数可以作为组合函数来制造下一个递减函数，以此类推。")]),t._v(" "),n("p",[t._v("让我们使用几个不同的值来测试一下我们的 "),n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("longAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nope"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// []")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("longAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hello"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["hello"]')]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("longAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hello world"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// []")]),t._v("\n")])])]),n("p",[n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v(" 工具滤除了既不够长也不够短的值，而且它是在同一个步骤中做了这两个过滤的。它是一个组合的递减函数！")]),t._v(" "),n("p",[t._v("再花点儿时间让它消化吸收。它还是有些让我混乱。")]),t._v(" "),n("p",[t._v("现在，把 "),n("code",[t._v("x(..)")]),t._v(" （大写递减函数生成器）代入组合之中：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" longAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("y")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("z")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" upperLongAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("x")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" longAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("正如 "),n("code",[t._v("upperLongAndShortEnoughReducer(..)")]),t._v(" 这个名字所暗示的，它一次完成所有三个步骤 —— 一个映射和两个过滤！它内部看起来就像这样：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// upperLongAndShortEnoughReducer:")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("longAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strUppercase")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("一个字符串 "),n("code",[t._v("val")]),t._v(" 被传入，由 "),n("code",[t._v("strUppercase(..)")]),t._v(" 改为大写，然后被传递给 "),n("code",[t._v("longAndShortEnoughReducer(..)")]),t._v("。这个函数仅条件性地 —— 如果这个字符串长短合适 —— 将这个大写字符串添加到 "),n("code",[t._v("list")]),t._v("，否则 "),n("code",[t._v("list")]),t._v(" 保持不变。")]),t._v(" "),n("p",[t._v("我的大脑花了好几周才完全理解了这套杂耍的含义。所以如果你需要在这里停下并重读几遍（几十遍！）来搞明白它也不要担心。慢慢来。")]),t._v(" "),n("p",[t._v("现在我们验证一下：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token function"}},[t._v("upperLongAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"nope"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// []")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("upperLongAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hello"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["HELLO"]')]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("upperLongAndShortEnoughReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hello world"')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// []")]),t._v("\n")])])]),n("p",[t._v("这个递减函数是一个映射函数和两个过滤函数的组合！这真是太妙了！")]),t._v(" "),n("p",[t._v("概括一下我们目前身在何处：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" x "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedMapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" z "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" upperLongAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("x")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("y")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("z")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nwords"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" upperLongAndShortEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n")])])]),n("p",[t._v("这很酷。但是我们可以做得更好。")]),t._v(" "),n("p",[n("code",[t._v("x(y(z( .. )))")]),t._v(" 是一个组合。让我们跳过中间的变量名 "),n("code",[t._v("x")]),t._v(" / "),n("code",[t._v("y")]),t._v(" / "),n("code",[t._v("z")]),t._v("，直接表达这个组合：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" composition "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedMapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" upperLongAndShortEnoughReducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("composition")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nwords"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" upperLongAndShortEnoughReducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n")])])]),n("p",[t._v("考虑一下这个组合函数的 “数据” 流：")]),t._v(" "),n("ol",[n("li",[n("code",[t._v("listCombine(..)")]),t._v(" 作为组合函数流入 "),n("code",[t._v("isShortEnough(..)")]),t._v("，为它制造了过滤-递减函数。")]),t._v(" "),n("li",[t._v("然后这个结果递减函数作为组合函数流入 "),n("code",[t._v("isLongEnough(..)")]),t._v("，为它制造了过滤-递减函数。")]),t._v(" "),n("li",[t._v("最后，这个结果递减函数作为组合函数流入 "),n("code",[t._v("strUppercase(..)")]),t._v("，为它制造了映射-递减函数。")])]),t._v(" "),n("p",[t._v("在前一个代码段中，"),n("code",[t._v("composition(..)")]),t._v(" 是一个组合好的函数，它期待一个组合函数来制造一个递减函数；"),n("code",[t._v("composition(..)")]),t._v(" 有一个特殊的名称：transducer。向一个 transducer 提供组合函数就生成了组合好的递减函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedMapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curriedFilterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\nwords\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n")])])]),n("p",[n("strong",[t._v("注意：")]),t._v(" 我们应当关注一下前两个代码段中的 "),n("code",[t._v("compose(..)")]),t._v(" 顺序，它可能有些令人糊涂。回忆一下我们原来例子中的链条，我们 "),n("code",[t._v("map(strUppercase)")]),t._v(" 然后 "),n("code",[t._v("filter(isLongEnough)")]),t._v(" 最后 "),n("code",[t._v("filter(isShortEnough)")]),t._v("；这些操作确实是按照这样的顺序发生的。但是在"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch4.md/#user-content-generalcompose"}},[t._v("第四章")]),t._v("中，我们学习了 "),n("code",[t._v("compose(..)")]),t._v(" 通常会以函数被罗列的相反方向运行它们。所以，为什么我们在 "),n("em",[t._v("这里")]),t._v(" 不需要反转顺序来得到我们期望的相同结果呢？来自于每个递减函数的 "),n("code",[t._v("combinerFn(..)")]),t._v(" 的抽象在底层反转了操作实际的实施顺序。所以与直觉相悖地，当你组合一个 transducer 时，你实际上要以你所期望的函数执行的顺序来罗列它们！")],1),t._v(" "),n("h4",{attrs:{id:"列表结合：纯粹-vs-不纯粹"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#列表结合：纯粹-vs-不纯粹","aria-hidden":"true"}},[t._v("#")]),t._v(" 列表结合：纯粹 vs 不纯粹")]),t._v(" "),n("p",[t._v("一个快速的旁注，让我们重温一下 "),n("code",[t._v("listCombine(..)")]),t._v("组合函数的实现：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("虽然这种方式是纯粹的，但是它对性能产生了负面的影响：在递减的每一步中，我们都创建了一个全新的数组，在它上面追加值，而是指上扔掉了前一个数组。会有许多数组被创建和扔掉，这对不仅对 CPU 很不好而且还会引发内存的垃圾回收。")]),t._v(" "),n("p",[t._v("性能好一些的，不纯粹版本：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("孤立地考虑一下 "),n("code",[t._v("listCombine(..)")]),t._v("，无疑它是不纯粹的，而这是我们通常想要避免的。但是，我们考虑的角度应当更高一些。")]),t._v(" "),n("p",[n("code",[t._v("listCombine(..)")]),t._v(" 根本不是我们要与之交互的函数。我们没有在程序的任何部分直接使用它，而是让 transducer 处理使用它。")]),t._v(" "),n("p",[t._v("回顾"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch5.html"}},[t._v("第五章")]),t._v("，我们声称降低副作用与定义纯函数的目标仅仅是向我们将要在程序中通篇使用的 API 级别的函数暴露纯函数。我们在一个纯函数内部观察了它的底层，只要它不违反外部纯粹性的约定，就可以为了性能而使用任何作弊的方法。")],1),t._v(" "),n("p",[n("code",[t._v("listCombine(..)")]),t._v(" 更像是一个 transducing 的内部实现细节 —— 事实上，它经常由一个 transducing 库提供给你！ —— 而非一个你平常在程序中与之交互的顶层方法。")]),t._v(" "),n("p",[t._v("关键是：我认为使用性能优化后的非纯粹版本的 "),n("code",[t._v("listCombine(..)")]),t._v(" 是完全可以接受的，甚至是明智的。但要确保你用了一段代码注释将它的非纯粹性记录下来！")]),t._v(" "),n("h3",{attrs:{id:"替换组合函数"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#替换组合函数","aria-hidden":"true"}},[t._v("#")]),t._v(" 替换组合函数")]),t._v(" "),n("p",[t._v("至此，这就是我们从 transducing 中衍生出的东西：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" listCombine "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[t._v("这相当好，但关于 transducing 我们手中还有最后一个技巧。而且老实说，我认为这部分才是使你至此做出的所有思维上的努力得到回报的东西。")]),t._v(" "),n("p",[t._v("我们能否 “组合” 这两个 "),n("code",[t._v("reduce(..)")]),t._v(" 调用使它们成为一个 "),n("code",[t._v("reduce(..)")]),t._v("？不幸的是，我们不能仅仅将 "),n("code",[t._v("strConcat(..)")]),t._v(" 加入 "),n("code",[t._v("compose(..)")]),t._v(" 调用；因为它是一个递减函数而非一个等待被组合的函数，它的外形对于这种组合来说不正确。")]),t._v(" "),n("p",[t._v("但让我肩并肩地看看这两个函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("strConcat")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("str1"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("str2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" str1 "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" str2"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("listCombine")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("val")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("push")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" val "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("如果你眯起眼，你就能看到这两个函数几乎是可以互换的。它们操作不同的数据类型，但是在概念上它们做的是相同的事情：将两个值结合为一个。")]),t._v(" "),n("p",[t._v("换句话说，"),n("code",[t._v("strConcat(..)")]),t._v(" 是一个组合函数！")]),t._v(" "),n("p",[t._v("这意味着如果我们的最终目标是得到一个字符串链接而非一个列表的话，我们就可以使用它替换 "),n("code",[t._v("listCombine(..)")]),t._v("：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strConcat "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[t._v("轰！这就是你的 transducing。我不会真的在这里摔麦克，而是轻轻地将它放下……")]),t._v(" "),n("h2",{attrs:{id:"最后，是什么"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#最后，是什么","aria-hidden":"true"}},[t._v("#")]),t._v(" 最后，是什么")]),t._v(" "),n("p",[t._v("深呼吸。这真是有太多东西要消化了。")]),t._v(" "),n("p",[t._v("用几分钟清理一下大脑，摆脱所有那些推导它如何工作的思维圈子，让我们将注意力返回到在我们的应用程序中如何使用 transducing。")]),t._v(" "),n("p",[t._v("回忆一下我们早先定义的帮助函数；为了清晰让我们重命名它们：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transduceMap "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("mapperFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapperFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" v "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transduceFilter "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("curry")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filterReducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("predicateFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("v")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("predicateFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" v "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("combinerFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" v "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[t._v("再回忆一下我们是这样使用它们的：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceMap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceFilter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceFilter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),n("p",[n("code",[t._v("transducer(..)")]),t._v(" 仍然需要被传入一个组合函数（比如 "),n("code",[t._v("listCombine(..)")]),t._v(" 或 "),n("code",[t._v("strConcat(..)")]),t._v("）来生成一个 transduce-递减函数，然后这个函数才能在 "),n("code",[t._v("reduce(..)")]),t._v(" 中使用（与一个初始值一起）。")]),t._v(" "),n("p",[t._v("但是为了更具声明性地表达所有这些 transducing 步骤，让我们制造一个实施所有这些步骤的 "),n("code",[t._v("transduce(..)")]),t._v(" 工具：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("transducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("combinerFn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("initialValue"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("list")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" reducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transducer")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" combinerFn "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" list"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" reducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" initialValue "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),n("p",[t._v("这是我们清理过后的例子：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transducer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("compose")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceMap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceFilter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduceFilter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" transducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" listCombine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" transducer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[t._v("不赖吧！？看到 "),n("code",[t._v("listCombine(..)")]),t._v(" 和 "),n("code",[t._v("strConcat(..)")]),t._v(" 函数作为组合函数被互换地使用了吗？")]),t._v(" "),n("h3",{attrs:{id:"transducers-js"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#transducers-js","aria-hidden":"true"}},[t._v("#")]),t._v(" Transducers.js")]),t._v(" "),n("p",[t._v("最后，让我们使用 "),n("a",{attrs:{href:"https://github.com/cognitect-labs/transducers-js",target:"_blank",rel:"noopener noreferrer"}},[n("code",[t._v("transducers-js")]),t._v(" 库"),n("OutboundLink")],1),t._v("来展示我们的例子：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("var")]),t._v(" transformer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("comp")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" strUppercase "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isLongEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("filter")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" isShortEnough "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\ntransducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" listCombine"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n\ntransducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("transduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" strConcat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[t._v("这看起来几乎和上面一模一样。")]),t._v(" "),n("p",[n("strong",[t._v("注意：")]),t._v(" 上面的代码段使用 "),n("code",[t._v("transformers.comp(..)")]),t._v(" 是因为库提供了它，但在这种情况下我们"),n("router-link",{attrs:{to:"/module_book/JS/Functional-Light-JS-zh/ch4.md/#user-content-generalcompose"}},[t._v("第四章的 "),n("code",[t._v("compose(..)")])]),t._v(" 将生成相同的结果。换言之，组合本身不是一个 transducing 敏感的操作。")],1),t._v(" "),n("p",[t._v("在这个代码段中，组合好的函数被命名为 "),n("code",[t._v("transformer")]),t._v(" 而不是 "),n("code",[t._v("transducer")]),t._v("。这是因为如果我们调用 "),n("code",[t._v("transformer( listCombine )")]),t._v("（或者 "),n("code",[t._v("transformer( strConcat )")]),t._v("），我们不会像之前那样直接得到 transduce-递减函数。")]),t._v(" "),n("p",[n("code",[t._v("transducers.map(..)")]),t._v(" 和 "),n("code",[t._v("transducers.filter(..)")]),t._v(" 是特殊的帮助函数，它们将普通的判定或映射函数适配为生成一个特殊（在底层包装了一个 transducer 函数的）变形对象的函数；这个库将这些变形对象用于 transducing。这个变形函数抽象的额外能力超出了我们要探索的范围，更多的信息请参阅这个库的文档。")]),t._v(" "),n("p",[t._v("因为调用 "),n("code",[t._v("transformer(..)")]),t._v(" 会生成一个变形对象，而且不是一个典型的二元 transduce-递减函数，所以库还提供了 "),n("code",[t._v("toFn(..)")]),t._v(" 来将这个变形对象适配为可以被原生数组 "),n("code",[t._v("reduce(..)")]),t._v(" 使用的函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("words"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("reduce")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("toFn")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" strConcat "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[n("code",[t._v("into(..)")]),t._v(" 是库提供的另一个帮助函数，它根据被指定的空/初始值类型自动地选择一个默认组合函数：")]),t._v(" "),n("div",{staticClass:"language-js extra-class"},[n("pre",{pre:!0,attrs:{class:"language-js"}},[n("code",[t._v("transducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("into")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// ["WRITTEN","SOMETHING"]')]),t._v("\n\ntransducers"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("into")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" transformer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" words "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// WRITTENSOMETHING")]),t._v("\n")])])]),n("p",[t._v("当指定一个空数组 "),n("code",[t._v("[]")]),t._v(" 时，在底层被调用的 "),n("code",[t._v("transduce(..)")]),t._v(" 使用一个默认的函数实现，它就像我们的 "),n("code",[t._v("listCombine(..)")]),t._v(" 帮助函数。但当指定一个空字符串 "),n("code",[t._v('""')]),t._v(" 时，一个如我们 "),n("code",[t._v("strConcat(..)")]),t._v(" 的函数就会被使用。酷！")]),t._v(" "),n("p",[t._v("如你所见，"),n("code",[t._v("transducers-js")]),t._v(" 库使得 transducing 变得相当直接了当。我们可以非常高效地利用这种技术的力量，而不必亲自深入所有这些定义中间 transducer 生成工具的过程。")]),t._v(" "),n("h2",{attrs:{id:"总结"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#总结","aria-hidden":"true"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),n("p",[t._v("Transduce 意味着使用递减来变形。更具体点儿说，一个 transducer 是一个可以进行组合的递减函数。")]),t._v(" "),n("p",[t._v("我们使用 transducing 将相邻的 "),n("code",[t._v("map(..)")]),t._v("、"),n("code",[t._v("filter(..)")]),t._v("、以及 "),n("code",[t._v("reduce(..)")]),t._v(" 组合在一起。我们是这样做到的：首先将 "),n("code",[t._v("map(..)")]),t._v(" 和 "),n("code",[t._v("filter(..)")]),t._v(" 表达为 "),n("code",[t._v("reduce(..)")]),t._v("，然后将共通的组合操作抽象出来，创建一个很容易组合的一元递减函数生成函数。")]),t._v(" "),n("p",[t._v("Transducing 主要改善了新能，这在用于一个 observable 时尤其明显。")]),t._v(" "),n("p",[t._v("但更广泛地说，transducing 是我们如何将不能直接组合的函数表达为声明性更强的函数组合的方式。如果与本书中的其他技术一起恰当地使用，它就能产生更干净，可读性更强的代码！推理一个使用 transducer 的单独 "),n("code",[t._v("reduce(..)")]),t._v(" 调用，要比跟踪多个 "),n("code",[t._v("reduce(..)")]),t._v(" 调用容易许多。")])])},[],!1,null,null,null);s.default=e.exports}}]);